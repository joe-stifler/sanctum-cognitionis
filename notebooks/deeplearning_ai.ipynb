{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake_useragent in /home/joe/anaconda3/envs/acse-irp/lib/python3.10/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://platform.openai.com/docs/guides/images/usage?context=node: 403 Client Error: Forbidden for url: https://platform.openai.com/docs/guides/images/usage?context=node\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "\n",
    "def html_to_markdown(url, soup):\n",
    "    \"\"\"\n",
    "    Converts HTML content to Markdown.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object representing the HTML content.\n",
    "\n",
    "    Returns:\n",
    "        str: The Markdown content.\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_content = \"\"\n",
    "\n",
    "    # Handle headings\n",
    "    for heading in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "        level = int(heading.name[1:])\n",
    "        markdown_content += f\"{'#' * level} {heading.text.strip()}\\n\\n\"\n",
    "\n",
    "    # Handle paragraphs\n",
    "    for paragraph in soup.find_all(\"p\"):\n",
    "        markdown_content += f\"{paragraph.text.strip()}\\n\\n\"\n",
    "\n",
    "    # Handle images\n",
    "    for image in soup.find_all(\"img\"):\n",
    "        alt_text = image.get(\"alt\", \"\")\n",
    "        src = image.get(\"src\", \"\")\n",
    "        if src:\n",
    "            markdown_content += f\"![{alt_text}]({urljoin(url, src)})\\n\\n\"\n",
    "\n",
    "    # Handle links\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        text = link.text.strip()\n",
    "        href = link.get(\"href\", \"\")\n",
    "        if href:\n",
    "            markdown_content += f\"[{text}]({urljoin(url, href)})\\n\\n\"\n",
    "\n",
    "    # Handle lists\n",
    "    for list_tag in soup.find_all([\"ul\", \"ol\"]):\n",
    "        list_items = list_tag.find_all(\"li\")\n",
    "        if list_tag.name == \"ul\":\n",
    "            markdown_content += (\n",
    "                \"- \" + \"\\n- \".join([item.text.strip() for item in list_items]) + \"\\n\\n\"\n",
    "            )\n",
    "        else:\n",
    "            markdown_content += (\n",
    "                \"1. \"\n",
    "                + \"\\n1. \".join([item.text.strip() for item in list_items])\n",
    "                + \"\\n\\n\"\n",
    "            )\n",
    "\n",
    "    # Handle code blocks\n",
    "    for code_block in soup.find_all(\"code\"):\n",
    "        markdown_content += f\"```\\n{code_block.text.strip()}\\n```\\n\\n\"\n",
    "\n",
    "    # Handle blockquotes\n",
    "    for blockquote in soup.find_all(\"blockquote\"):\n",
    "        markdown_content += f\"> {blockquote.text.strip()}\\n\\n\"\n",
    "\n",
    "    # Handle iframes (e.g., embedded videos)\n",
    "    for iframe in soup.find_all(\"iframe\"):\n",
    "        src = iframe.get(\"src\", \"\")\n",
    "        if src:\n",
    "            markdown_content += f\"[Embedded content]({urljoin(url, src)})\\n\\n\"\n",
    "\n",
    "    # Handle horizontal rules\n",
    "    for hr in soup.find_all(\"hr\"):\n",
    "        markdown_content += \"---\\n\\n\"\n",
    "\n",
    "    # Handle tables\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        rows = table.find_all(\"tr\")\n",
    "        headers = [th.text.strip() for th in rows[0].find_all(\"th\")]\n",
    "        markdown_content += \"| \" + \" | \".join(headers) + \" |\\n\"\n",
    "        markdown_content += \"|-\" * len(headers) + \"|\\n\"\n",
    "        for row in rows[1:]:\n",
    "            cells = [td.text.strip() for td in row.find_all([\"td\", \"th\"])]\n",
    "            markdown_content += \"| \" + \" | \".join(cells) + \" |\\n\"\n",
    "        markdown_content += \"\\n\"\n",
    "\n",
    "    # Replace multiple newlines with a single newline\n",
    "    markdown_content = re.sub(r\"\\n+\", \"\\n\\n\", markdown_content)\n",
    "\n",
    "    return markdown_content\n",
    "\n",
    "\n",
    "def scrape_urls_to_markdown_and_html(urls, output_prefix=\"scraped_content\"):\n",
    "    \"\"\"\n",
    "    Scrapes HTML content from a list of URLs and saves the textual content\n",
    "    for each URL in both a Markdown and an HTML file, converting any html tag\n",
    "    that can be mapped directly to markdown into markdown.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs to scrape.\n",
    "        output_prefix (str, optional): The prefix for the output file names.\n",
    "            Defaults to \"scraped_content\".\n",
    "    \"\"\"\n",
    "\n",
    "    final_markdown_content = \"\"\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            # Use a more generic User-Agent\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\",\n",
    "                \"Connection\": \"keep-alive\",\n",
    "                \"Upgrade-Insecure-Requests\": \"1\",\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\", from_encoding=\"utf-8\")\n",
    "\n",
    "            # Remove scripts and styles\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()\n",
    "\n",
    "            # Remove any template tags\n",
    "            for template in soup([\"template\"]):\n",
    "                template.extract()\n",
    "\n",
    "            # Remove all div tags and preserve their content\n",
    "            for div in soup.find_all(\"div\"):\n",
    "                div.unwrap()\n",
    "\n",
    "            # Remove all span tags and preserve their content\n",
    "            for span in soup.find_all(\"span\"):\n",
    "                span.unwrap()\n",
    "\n",
    "            # Remove all meta tags and preserve their content\n",
    "            for meta in soup.find_all(\"meta\"):\n",
    "                meta.unwrap()\n",
    "\n",
    "            # Remove all link tags and preserve their content\n",
    "            for link in soup.find_all(\"link\"):\n",
    "                link.unwrap()\n",
    "\n",
    "            # Remove class attributes from all tags\n",
    "            for tag in soup.find_all(True, attrs={\"class\": True}):\n",
    "                del tag[\"class\"]\n",
    "\n",
    "            # Save HTML content\n",
    "            with open(f\"{output_prefix}_{i}.html\", \"w\", encoding=\"utf-8\") as html_file:\n",
    "                html_file.write(soup.prettify())\n",
    "\n",
    "            # Convert HTML to Markdown\n",
    "            markdown_content = html_to_markdown(url, soup)\n",
    "\n",
    "            # Wrap the Markdown content in details tag\n",
    "            markdown_content = (\n",
    "                f\"<details><summary>{url}</summary>\\n\\n{markdown_content}\\n</details>\"\n",
    "            )\n",
    "\n",
    "            # Save Markdown content\n",
    "            with open(f\"{output_prefix}_{i}.md\", \"w\", encoding=\"utf-8\") as md_file:\n",
    "                md_file.write(markdown_content)\n",
    "\n",
    "            # Append to final Markdown content\n",
    "            final_markdown_content += markdown_content + \"\\n\\n\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "    # Save final merged Markdown content\n",
    "    with open(f\"{output_prefix}_merged.md\", \"w\", encoding=\"utf-8\") as merged_md_file:\n",
    "        merged_md_file.write(final_markdown_content)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "urls = [\n",
    "    # \"https://llama.meta.com/docs/model-cards-and-prompt-formats/\",\n",
    "    \"https://platform.openai.com/docs/guides/images/usage?context=node\"\n",
    "]\n",
    "\n",
    "scrape_urls_to_markdown_and_html(urls, \"scraped_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag\",\n",
    "    \"https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai\",\n",
    "    \"https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex\",\n",
    "    \"https://www.deeplearning.ai/short-courses/quantization-in-depth\",\n",
    "    \"https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models\",\n",
    "    \"https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications\",\n",
    "    \"https://www.deeplearning.ai/short-courses/red-teaming-llm-applications\",\n",
    "    \"https://www.deeplearning.ai/short-courses/getting-started-with-mistral\",\n",
    "    \"https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face\",\n",
    "    \"https://www.deeplearning.ai/short-courses/efficiently-serving-llms\",\n",
    "    \"https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex\",\n",
    "    \"https://www.deeplearning.ai/short-courses/open-source-models-hugging-face\",\n",
    "    \"https://www.deeplearning.ai/short-courses/knowledge-graphs-rag\",\n",
    "    \"https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2\",\n",
    "    \"https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-applications-vector-databases\",\n",
    "    \"https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js\",\n",
    "    \"https://www.deeplearning.ai/short-courses/automated-testing-llmops\",\n",
    "    \"https://www.deeplearning.ai/short-courses/llmops\",\n",
    "    \"https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai\",\n",
    "    \"https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag\",\n",
    "    \"https://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications\",\n",
    "    \"https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain\",\n",
    "    \"https://www.deeplearning.ai/short-courses/quality-safety-llm-applications\",\n",
    "    \"https://www.deeplearning.ai/short-courses/pair-programming-llm\",\n",
    "    \"https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/\",\n",
    "    \"https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai\",\n",
    "    \"https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel\",\n",
    "    \"https://www.deeplearning.ai/short-courses/finetuning-large-language-models\",\n",
    "    \"https://www.deeplearning.ai/short-courses/large-language-models-semantic-search\",\n",
    "    \"https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai\",\n",
    "    \"https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio\",\n",
    "    \"https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt\",\n",
    "    \"https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development\",\n",
    "    \"https://www.deeplearning.ai/short-courses/how-diffusion-models-work\",\n",
    "    \"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers\",\n",
    "]\n",
    "scrape_urls_to_markdown_and_html(urls, output_prefix=\"short_courses/short_courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_courses = [\n",
    "    \"https://www.deeplearning.ai/courses/machine-learning-in-production/\",\n",
    "    \"https://www.deeplearning.ai/courses/generative-ai-for-everyone/\",\n",
    "    \"https://www.deeplearning.ai/courses/generative-ai-with-llms/\",\n",
    "    \"https://www.deeplearning.ai/courses/ai-for-everyone/\",\n",
    "]\n",
    "scrape_urls_to_markdown_and_html(urls_courses, output_prefix=\"courses/courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_specializations = [\n",
    "    \"https://www.deeplearning.ai/courses/machine-learning-in-production/\",\n",
    "    \"https://www.deeplearning.ai/courses/generative-ai-for-everyone/\",\n",
    "    \"https://www.deeplearning.ai/courses/generative-ai-with-llms/\",\n",
    "    \"https://www.deeplearning.ai/courses/ai-for-everyone/\",\n",
    "]\n",
    "scrape_urls_to_markdown_and_html(\n",
    "    url_specializations, output_prefix=\"specialization/specializations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/: 429 Client Error: Too Many Requests for url: https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/\n"
     ]
    }
   ],
   "source": [
    "urls_notebooks = [\n",
    "    \"https://www.ollama.com/\",\n",
    "    \"https://ai.google.dev/gemma/docs\",\n",
    "    \"https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/\",\n",
    "    \"https://huggingface.co/models\",\n",
    "    \"https://python.langchain.com/\",\n",
    "    \"https://faiss.ai/\",\n",
    "    \"https://docs.trychroma.com/\",\n",
    "    \"https://www.pinecone.io/\",\n",
    "    \"https://www.devitoproject.org/\",\n",
    "    \"https://www.devitoproject.org/tutorials.html\",\n",
    "    \"https://www.devitoproject.org/api/\",\n",
    "    \"https://python.langchain.com/\",\n",
    "    \"https://python.langchain.com/v0.2/docs/tutorials/rag/\",\n",
    "    \"https://python.langchain.com/v0.1/docs/use_cases/question_answering/\",\n",
    "    \"https://ai.google.dev/\",\n",
    "]\n",
    "scrape_urls_to_markdown_and_html(\n",
    "    urls_notebooks, output_prefix=\"llm-sig-urls/llm-sig-urls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_prompt_engineering = [\n",
    "    \"https://www.promptingguide.ai/introduction\",\n",
    "    \"https://www.promptingguide.ai/introduction/settings\",\n",
    "    \"https://www.promptingguide.ai/introduction/basics\",\n",
    "    \"https://www.promptingguide.ai/introduction/elements\",\n",
    "    \"https://www.promptingguide.ai/introduction/tips\",\n",
    "    \"https://www.promptingguide.ai/introduction/examples\",\n",
    "    \"https://www.promptingguide.ai/techniques\",\n",
    "    \"https://www.promptingguide.ai/techniques/zeroshot\",\n",
    "    \"https://www.promptingguide.ai/techniques/fewshot\",\n",
    "    \"https://www.promptingguide.ai/techniques/cot\",\n",
    "    \"https://www.promptingguide.ai/techniques/consistency\",\n",
    "    \"https://www.promptingguide.ai/techniques/knowledge\",\n",
    "    \"https://www.promptingguide.ai/techniques/prompt_chaining\",\n",
    "    \"https://www.promptingguide.ai/techniques/tot\",\n",
    "    \"https://www.promptingguide.ai/techniques/rag\",\n",
    "    \"https://www.promptingguide.ai/techniques/art\",\n",
    "    \"https://www.promptingguide.ai/techniques/ape\",\n",
    "    \"https://www.promptingguide.ai/techniques/activeprompt\",\n",
    "    \"https://www.promptingguide.ai/techniques/dsp\",\n",
    "    \"https://www.promptingguide.ai/techniques/pal\",\n",
    "    \"https://www.promptingguide.ai/techniques/react\",\n",
    "    \"https://www.promptingguide.ai/techniques/reflexion\",\n",
    "    \"https://www.promptingguide.ai/techniques/multimodalcot\",\n",
    "    \"https://www.promptingguide.ai/techniques/graph\",\n",
    "    \"https://www.promptingguide.ai/applications\",\n",
    "    \"https://www.promptingguide.ai/applications/function_calling\",\n",
    "    \"https://www.promptingguide.ai/applications/generating\",\n",
    "    \"https://www.promptingguide.ai/applications/synthetic_rag\",\n",
    "    \"https://www.promptingguide.ai/applications/generating_textbooks\",\n",
    "    \"https://www.promptingguide.ai/applications/coding\",\n",
    "    \"https://www.promptingguide.ai/applications/workplace_casestudy\",\n",
    "    \"https://www.promptingguide.ai/applications/pf\",\n",
    "    \"https://www.promptingguide.ai/prompts\",\n",
    "    \"https://www.promptingguide.ai/prompts/classification\",\n",
    "    \"https://www.promptingguide.ai/prompts/coding\",\n",
    "    \"https://www.promptingguide.ai/prompts/creativity\",\n",
    "    \"https://www.promptingguide.ai/prompts/evaluation\",\n",
    "    \"https://www.promptingguide.ai/prompts/information-extraction\",\n",
    "    \"https://www.promptingguide.ai/prompts/image-generation\",\n",
    "    \"https://www.promptingguide.ai/prompts/mathematics\",\n",
    "    \"https://www.promptingguide.ai/prompts/question-answering\",\n",
    "    \"https://www.promptingguide.ai/prompts/reasoning\",\n",
    "    \"https://www.promptingguide.ai/prompts/text-summarization\",\n",
    "    \"https://www.promptingguide.ai/prompts/truthfulness\",\n",
    "    \"https://www.promptingguide.ai/prompts/adversarial-prompting\",\n",
    "    \"https://www.promptingguide.ai/models\",\n",
    "    \"https://www.promptingguide.ai/models/chatgpt\",\n",
    "    \"https://www.promptingguide.ai/models/claude-3\",\n",
    "    \"https://www.promptingguide.ai/models/code-llama\",\n",
    "    \"https://www.promptingguide.ai/models/flan\",\n",
    "    \"https://www.promptingguide.ai/models/gemini\",\n",
    "    \"https://www.promptingguide.ai/models/gemini-advanced\",\n",
    "    \"https://www.promptingguide.ai/models/gemini-pro\",\n",
    "    \"https://www.promptingguide.ai/models/gemma\",\n",
    "    \"https://www.promptingguide.ai/models/gpt-4\",\n",
    "    \"https://www.promptingguide.ai/models/grok-1\",\n",
    "    \"https://www.promptingguide.ai/models/llama\",\n",
    "    \"https://www.promptingguide.ai/models/llama-3\",\n",
    "    \"https://www.promptingguide.ai/models/mistral-7b\",\n",
    "    \"https://www.promptingguide.ai/models/mistral-large\",\n",
    "    \"https://www.promptingguide.ai/models/mixtral\",\n",
    "    \"https://www.promptingguide.ai/models/mixtral-8x22b\",\n",
    "    \"https://www.promptingguide.ai/models/olmo\",\n",
    "    \"https://www.promptingguide.ai/models/phi-2\",\n",
    "    \"https://www.promptingguide.ai/models/sora\",\n",
    "    \"https://www.promptingguide.ai/models/collection\",\n",
    "    \"https://www.promptingguide.ai/risks\",\n",
    "    \"https://www.promptingguide.ai/risks/adversarial\",\n",
    "    \"https://www.promptingguide.ai/risks/factuality\",\n",
    "    \"https://www.promptingguide.ai/risks/biases\",\n",
    "    \"https://www.promptingguide.ai/research\",\n",
    "    \"https://www.promptingguide.ai/research/llm-agents\",\n",
    "    \"https://www.promptingguide.ai/research/rag\",\n",
    "    \"https://www.promptingguide.ai/research/llm-reasoning\",\n",
    "    \"https://www.promptingguide.ai/research/rag-faithfulness\",\n",
    "    \"https://www.promptingguide.ai/research/llm-recall\",\n",
    "    \"https://www.promptingguide.ai/research/rag_hallucinations\",\n",
    "    \"https://www.promptingguide.ai/research/synthetic_data\",\n",
    "    \"https://www.promptingguide.ai/research/thoughtsculpt\",\n",
    "    \"https://www.promptingguide.ai/research/infini-attention\",\n",
    "    \"https://www.promptingguide.ai/research/guided-cot\",\n",
    "    \"https://www.promptingguide.ai/research/trustworthiness-in-llms\",\n",
    "    \"https://www.promptingguide.ai/research/llm-tokenization\",\n",
    "    \"https://www.promptingguide.ai/research/groq\",\n",
    "    \"https://www.promptingguide.ai/papers\",\n",
    "    \"https://www.promptingguide.ai/tools\",\n",
    "    \"https://www.promptingguide.ai/notebooks\",\n",
    "    \"https://www.promptingguide.ai/datasets\",\n",
    "    \"https://www.promptingguide.ai/readings\",\n",
    "]\n",
    "scrape_urls_to_markdown_and_html(\n",
    "    urls_prompt_engineering, output_prefix=\"prompt_engineering/prompt_engineering\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acse-irp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
